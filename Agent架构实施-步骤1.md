# Agent Orchestration æ¶æ„å®æ–½ - å®Œæ•´æ­¥éª¤

## ğŸ¯ ç›®æ ‡

å°†æƒ…ç»ªåˆ†æä»åé¦ˆç”Ÿæˆä¸­åˆ†ç¦»,åˆ›å»ºä¸“é—¨çš„ Emotion Agent,æå‡å‡†ç¡®åº¦ 15-20%

## ğŸ“‹ å®æ–½æ­¥éª¤

### æ­¥éª¤ 1: æ·»åŠ ä¸“é—¨çš„æƒ…ç»ªåˆ†æ Agent

**æ–‡ä»¶**: `backend/app/services/openai_service.py`
**ä½ç½®**: åœ¨ç¬¬ 1195 è¡Œä¹‹å (åœ¨ `_validate_and_fix_result` æ–¹æ³•ä¹‹å‰)

**æ·»åŠ ä»¥ä¸‹ä»£ç **:

```python
    # ========================================================================
    # ğŸ”¥ æ–°å¢: ä¸“é—¨çš„æƒ…ç»ªåˆ†æAgent (Agent Orchestration æ¶æ„)
    # ========================================================================

    async def analyze_emotion_only(
        self,
        text: str,
        language: str,
        encoded_images: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        âœ… æ–°å¢: ä¸“é—¨çš„æƒ…ç»ªåˆ†æAgent

        èŒè´£: åªåšæƒ…ç»ªåˆ†æ,ä¸ç”Ÿæˆåé¦ˆ
        ä¼˜åŠ¿:
        - Promptæ›´çŸ­ (300 tokens vs 1050 tokens)
        - æ›´ä¸“æ³¨,å‡†ç¡®åº¦æ›´é«˜
        - å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„åˆ†æé€»è¾‘

        è¿”å›:
            {
                "emotion": "Fulfilled",
                "confidence": 0.92,
                "rationale": "ç”¨æˆ·å®Œæˆäº†é¡¹ç›®,è¡¨è¾¾äº†æˆå°±æ„Ÿå’Œæ»¡è¶³æ„Ÿ"
            }
        """
        try:
            print(f"ğŸ¯ Emotion Agent: å¼€å§‹ä¸“ä¸šæƒ…ç»ªåˆ†æ...")

            # âœ… ç²¾ç®€çš„System Prompt (åªå…³æ³¨æƒ…ç»ªåˆ†æ)
            system_prompt = f"""You are an expert emotion analyst specializing in psychological assessment.

Your ONLY task: Analyze the user's emotion from their text/images.

ğŸ¯ EMOTION CATEGORIES (23 emotions):

**Positive (8)**: Joyful, Grateful, Fulfilled, Proud, Surprised, Excited, Peaceful, Hopeful
**Neutral (7)**: Thoughtful, Reflective, Intentional, Inspired, Curious, Nostalgic, Calm
**Negative (8)**: Uncertain, Misunderstood, Lonely, Down, Anxious, Overwhelmed, Venting, Frustrated

ğŸ“Š ANALYSIS RULES:

1. **Precision over Speed**: Take time to analyze carefully
2. **Context Matters**: Consider the full context, not just keywords
3. **Confidence Score**:
   - 0.9-1.0: Very clear emotion (explicit keywords + context)
   - 0.7-0.9: Clear emotion (context supports)
   - 0.5-0.7: Moderate (some ambiguity)
   - 0.3-0.5: Uncertain (default to Thoughtful)

4. **Detailed Rationale**: Explain WHY you chose this emotion

ğŸ¯ KEY EMOTION DEFINITIONS:

**Fulfilled (å……å®)** - Achievement & Completion:
- Keywords: "å®Œæˆ", "è¾¾æˆ", "å®ç°", "æˆå°±", "æ”¶è·", "accomplished", "completed", "achieved"
- Context: Finished tasks, learned skills, made progress
- Example: "å®Œæˆäº†é¡¹ç›®" â†’ Fulfilled (NOT Joyful)

**Joyful (å–œæ‚¦)** - Pure Happiness:
- Keywords: "å¼€å¿ƒ", "å¿«ä¹", "é«˜å…´", "happy", "fun", "joy"
- Context: Spontaneous happiness, celebration, not tied to achievement
- Example: "å’Œæœ‹å‹ç©å¾—å¾ˆå¼€å¿ƒ" â†’ Joyful

**Thoughtful (è‹¥æœ‰æ‰€æ€)** - DEFAULT:
- General thinking, pondering, recording
- Use when emotion is unclear or neutral

**Grateful (æ„Ÿæ©)** - Thankfulness:
- Keywords: "æ„Ÿè°¢", "æ„Ÿæ©", "grateful", "thankful"

**Excited (æœŸå¾…)** - Anticipation:
- Keywords: "æœŸå¾…", "ç­‰å¾…", "can't wait", "looking forward"

**Anxious (ç„¦è™‘)** - Worry:
- Keywords: "ç„¦è™‘", "æ‹…å¿ƒ", "ç´§å¼ ", "anxious", "worried"

**Down (ä½è½)** - Sadness:
- Keywords: "éš¾è¿‡", "å¤±è½", "æ²®ä¸§", "sad", "down"

**Overwhelmed (ä¸å ªé‡è´Ÿ)** - Stressed:
- Keywords: "å‹åŠ›å¤§", "å¿™ä¸è¿‡æ¥", "overwhelmed"

âš ï¸ CRITICAL RULES:
- Choose the MOST SPECIFIC emotion
- Fulfilled vs Joyful: Fulfilled = achievement, Joyful = spontaneous happiness
- When in doubt, use Thoughtful
- Consider BOTH keywords AND context

Response Format (JSON):
{{
    "emotion": "Fulfilled",
    "confidence": 0.92,
    "rationale": "ç”¨æˆ·å®Œæˆäº†é¡¹ç›®,æ˜ç¡®è¡¨è¾¾äº†æˆå°±æ„Ÿã€‚"
}}
"""

            # æ„å»ºæ¶ˆæ¯
            messages = [
                {"role": "system", "content": system_prompt}
            ]

            # æ„å»ºç”¨æˆ·æ¶ˆæ¯
            user_content = []

            # å¦‚æœæœ‰å›¾ç‰‡,æ·»åŠ å›¾ç‰‡
            if encoded_images and len(encoded_images) > 0:
                print(f"ğŸ–¼ï¸ æ·»åŠ  {len(encoded_images)} å¼ å›¾ç‰‡åˆ°æƒ…ç»ªåˆ†æ...")
                for image_data in encoded_images:
                    user_content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_data}",
                            "detail": "low"
                        }
                    })

                user_content.append({
                    "type": "text",
                    "text": f"è¯·åˆ†æä»¥ä¸‹å†…å®¹çš„æƒ…ç»ª(è€ƒè™‘å›¾ç‰‡å’Œæ–‡å­—):\\n\\n{text}"
                })
                user_prompt = user_content
            else:
                user_prompt = f"è¯·åˆ†æä»¥ä¸‹å†…å®¹çš„æƒ…ç»ª:\\n\\n{text}"

            messages.append({"role": "user", "content": user_prompt})

            # è°ƒç”¨GPT-4o-mini
            response = self.openai_client.chat.completions.create(
                model=self.MODEL_CONFIG["sonnet"],
                messages=messages,
                temperature=0.3,  # é™ä½æ¸©åº¦,æé«˜ä¸€è‡´æ€§
                response_format={"type": "json_object"},
                max_tokens=500
            )

            result = json.loads(response.choices[0].message.content)

            print(f"âœ… Emotion Agent åˆ†æå®Œæˆ:")
            print(f"   - æƒ…ç»ª: {result.get('emotion')}")
            print(f"   - ç½®ä¿¡åº¦: {result.get('confidence')}")
            print(f"   - ç†ç”±: {result.get('rationale')[:50]}...")

            return result

        except Exception as e:
            print(f"âŒ Emotion Agent å¤±è´¥: {str(e)}")
            return {
                "emotion": "Thoughtful",
                "confidence": 0.5,
                "rationale": "åˆ†æå¤±è´¥,ä½¿ç”¨é»˜è®¤æƒ…ç»ª"
            }
```

---

## â±ï¸ é¢„è®¡æ—¶é—´: 2 åˆ†é’Ÿ

å®Œæˆåè¯·å‘Šè¯‰æˆ‘,æˆ‘ä»¬ç»§ç»­ä¸‹ä¸€æ­¥!
